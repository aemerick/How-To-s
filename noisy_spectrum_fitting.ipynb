{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is a brief how-to on using my changes to the spectrum fitter in yt. The changes were first motivated to better handle noisy spectra, but have since then included modifications that allow for better handling of saturated (damped) lines and blended features. The edits also significantly limit the number of components fit to a given absorbtion region (i.e. an additional 'absorber' is added to fit a given absorption feature only if actually necessary / reasonable). Previoulsy, some feautures would be over-fit (with sometimes > 5 'absorbers' used to fit a given feature, most of which with column << the the first absorber fit to the feature). Keep in mind, the testing I have done has been ONLY for Lyman Alpha. The code should work for any line though, so long as: 1) that is the only line in the given spectrum, and 2) the line is a singlet. I have not tested any more general cases..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The code (well sort of...)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from yt.mods import *\n",
      "from yt.analysis_modules.api import *\n",
      "from yt.analysis_modules.cosmological_observation.light_ray.api import LightRay\n",
      "from yt.analysis_modules.absorption_spectrum.api import generate_total_fit\n",
      "# The above imports should be the same as before.... nothing new here...\n",
      "\n",
      "# to read from the .fits file\n",
      "import pyfits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in wavelength and flux data from a spectra that was generated previously... \n",
      "# I've only tested with normalized spectra... in principle this procedure could work more generally\n",
      "# with unnormalized continuum as long as one provides a fit to the continuum... this could be a \n",
      "# feature to add to the code in the future...\n",
      "hdulist = pyfits.open(\"absorption_spectrum.fits\")\n",
      "tbdata = hdulist[1].data\n",
      "wavelength = tbdata['wavelength']\n",
      "flux       = tbdata['flux']\n",
      "hdulist.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The below sets up the same dictionaries as was needed before my changes..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set the min, max, and start points for the N, b, z fits...\n",
      "# Please note that my changes to the code DO NOT use the 'start' values... part of what my code does\n",
      "# is to choose a \"smart\" initial guess for N,b,z. But to preserve the previous fitting procedure,\n",
      "# this is required...\n",
      "fit_param =  { 'N': [1.E9, 1.E24, 1.E14],\n",
      "               'b': [ 5.0, 200.0,  35.0],\n",
      "               'z': [ -0.02,  0.02,  0.05]\n",
      "             }\n",
      "\n",
      "HI_parameters = {'name':'HI',\n",
      "                'f': [0.4164],\n",
      "                'Gamma':[6.265E8],\n",
      "                'wavelength':[1215.67],\n",
      "                'numLines':1, # 2 for doublet...\n",
      "                # next parameters give bounds/guesses for fitting\n",
      "                'maxN'  : fit_param['N'][1], 'minN': fit_param['N'][0],\n",
      "                'maxb'  : fit_param['b'][1], 'minb': fit_param['b'][0],\n",
      "                'maxz'  : fit_param['z'][1], 'minz': fit_param['z'][0],\n",
      "                'init_b': fit_param['b'][2],\n",
      "                'init_N': fit_param['N'][2]}    \n",
      "\n",
      "speciesDicts = {'HI':HI_parameters} # dictionary for fit parameters\n",
      "orderFits = ['HI'] # specifies order to fit lines \n",
      "\n",
      "#\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we fit!! "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# returns fitted lines and fitted flux as before, and also the reduced chi squared...\n",
      "# PLEASE NOTE: The return of the  reduced chi squared is currently broken...\n",
      "# The new arguments below are 'yError' and 'sigLevel' these should be explained in the doc string\n",
      "# for generate_total_fit, but 'yError' should be the uncertainty/error on the flux in each bin\n",
      "# of the spectrum. 'sigLevel' gives the significance (i.e. number if sigma) above the noise you \n",
      "# require for something to be identified as a region to fit\n",
      "#\n",
      "# The fitting procedure works for pristine spectra so long as something is provided for yError\n",
      "# In the code, if yError is the default (None), the spectrum fitting will revert to the previous\n",
      "# version that was in yt as of sometime last Fall (not sure if changes have been made since then).\n",
      "\n",
      "# As you can see 'error_array' is not defined in this notebook and so the following command won't work\n",
      "#\n",
      "fitted_lines, fitted_flux, red_chi_sqr =generate_total_fit(wavelength, flux, orderFits, speciesDicts,\n",
      "                                                            yError = error_array, sigLevel = 3.0)\n",
      "#\n",
      "# However, you can have 'generate_total_fit' generate some gaussian random noise for you if you want\n",
      "# by specifying a desired SNR:\n",
      "fitted_lines, fitted_flux, red_chi_sqr =generate_total_fit(wavelength, flux, orderFits, speciesDicts,\n",
      "                                                           generate_noise=True, snr=15)\n",
      "\n",
      "# alternatively, you can set 'generate_noise' = False (default), but provide an snr... this provides\n",
      "# an uncertainty for the flux, but doesn't generate any noise... \n",
      "fitted_lines, fitted_flux, red_chi_sqr =generate_total_fit(wavelength, flux, orderFits, speciesDicts,\n",
      "                                                           generate_noise=False, snr=15)\n",
      "\n",
      "# the below will have the code work as it did before my edits:\n",
      "#\n",
      "fitted_lines, fitted_flux  = generate_total_fit(wavelength, flux, orderFits, speciesDicts)\n",
      "#"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you look at the doc string for the generate_total_fit function, you'll notice that there are A LOT of kwargs. This is because there were a lot there to begin with, and I added three (all discussed above). However, when using my changes to the code, 'complexLim', 'fitLim', 'splitLim', 'minLim', and 'maxLim' are not used."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}